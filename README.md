# Transcritor de ReuniÃµes

AplicaÃ§Ã£o Python para transcriÃ§Ã£o automÃ¡tica de reuniÃµes com identificaÃ§Ã£o de palestrantes, geraÃ§Ã£o de resumos e insights. Desenvolvido como parte de projeto acadÃªmico.

## Recursos

- ğŸµ Processamento automÃ¡tico de arquivos de Ã¡udio
- ğŸ“ TranscriÃ§Ã£o usando modelo Whisper
- ğŸ‘¥ IdentificaÃ§Ã£o automÃ¡tica de palestrantes
- âœï¸ RevisÃ£o e correÃ§Ã£o do texto transcrito
- ğŸ“Š GeraÃ§Ã£o de resumos e insights
- ğŸ“‹ GeraÃ§Ã£o de relatÃ³rios formatados

## PrÃ©-requisitos

- Python 3.8 ou superior
- FFmpeg instalado no sistema
- Chave de API da OpenAI
- 4GB+ de RAM recomendado

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/TranscritorDeReunioes.git
cd TranscritorDeReunioes
```

2. Instale o uv (gerenciador de pacotes):
```bash
# No Windows (PowerShell como administrador):
(Invoke-WebRequest -Uri "https://astral.sh/uv/install.ps1" -UseBasicParsing).Content | powershell -c -

# No Linux/MacOS:
curl -LsSf https://astral.sh/uv/install.sh | sh
```

3. Configure o ambiente virtual e instale as dependÃªncias:
```bash
uv venv
# Windows:
.venv\Scripts\activate
# Linux/MacOS:
source .venv/bin/activate

uv pip install -r requirements.txt
```

4. Configure as variÃ¡veis de ambiente:
   - Crie um arquivo `.env` na raiz do projeto
   - Adicione sua chave da API OpenAI:
   ```
   OPENAI_API_KEY=sua-chave-aqui
   ```


5. Configure o Whisper.
O whisper pode ser um pouco complicado de instalar. Vamos fazer passo a passo:

   1) Primeiro, vamos garantir que vocÃª tem o Torch instalado (prÃ©-requisito do whisper):
     ```
         uv pip install torch torchvision torchaudio
      ```
   2) Depois, instalar o whisper diretamente do repositÃ³rio OpenAI:
 ```
      uv pip install git+https://github.com/openai/whisper.git

   3) Instalar as DependÃªncias NecessÃ¡rias.  Instale o Whisper da OpenAI ou o SpeechRecognition com uma ferramenta como PyDub para lidar com arquivos de Ã¡udio.
      ``` 
      pip install openai-whisper pydub SpeechRecognition
      ```


## Estrutura do Projeto

```
TranscritorDeReunioes/
â”œâ”€â”€ tools/              # Ferramentas modulares
â”œâ”€â”€ agents/             # DefiniÃ§Ãµes dos agentes
â”œâ”€â”€ tasks/              # DefiniÃ§Ãµes das tarefas
â”œâ”€â”€ tests/              # Testes automatizados
â”œâ”€â”€ data/
â”‚   â””â”€â”€ audio/         # DiretÃ³rio para arquivos de Ã¡udio
â”œâ”€â”€ output/            # DiretÃ³rio para arquivos gerados
â”œâ”€â”€ main.py            # Script principal
â””â”€â”€ requirements.txt   # DependÃªncias do projeto
```

## Uso

1. Coloque seu arquivo de Ã¡udio (.wav) na pasta `data/audio/`

2. Execute o script:
```bash
python main.py
```

3. Selecione o arquivo quando solicitado

4. Os resultados serÃ£o salvos na pasta `output/`:
   - `transcricao.md`: TranscriÃ§Ã£o completa
   - `relatorio_transcricao.md`: RelatÃ³rio com resumo e insights

## Desenvolvimento

Para executar os testes:
```bash
pytest
```

## SincronizaÃ§Ã£o com Git

- Os arquivos de Ã¡udio (.wav) nÃ£o sÃ£o sincronizados com o Git
- Mantenha seus arquivos de Ã¡udio em backup local
- NÃ£o commit arquivos sensÃ­veis ou chaves de API

## SoluÃ§Ã£o de Problemas

1. Erro de API OpenAI:
   - Verifique se a chave estÃ¡ corretamente configurada no arquivo `.env`
   - Verifique se sua chave tem crÃ©ditos disponÃ­veis

2. Erro de FFmpeg:
   - Certifique-se que o FFmpeg estÃ¡ instalado e acessÃ­vel no PATH do sistema

3. Erro de memÃ³ria:
   - Tente com arquivos de Ã¡udio menores
   - Verifique a disponibilidade de RAM

## Contribuindo

1. FaÃ§a um Fork do projeto
2. Crie sua Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a Branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## CrÃ©ditos

Desenvolvido utilizando:
- OpenAI Whisper para transcriÃ§Ã£o
- CrewAI para orquestraÃ§Ã£o de agentes
- OpenAI GPT-4 para processamento de linguagem natural